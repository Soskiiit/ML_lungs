{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берём [отсюда](https://www.kaggle.com/settings) токен и бросаем его в %USERPATH%/.kaggle/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исполняем следующие строки кода и наблюдаем за магией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "2023-12-03 19:12:54,131 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /api/v1/competitions/data/download-all/ml-intensive-yandex-autumn-2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: kaggle in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (1.5.16)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (10.1.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from torch) (2023.12.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from kaggle) (2023.11.17)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from kaggle) (4.66.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from kaggle) (2.1.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sss\\lml_git\\ml_lungs\\venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sss\\lML_git\\ML_lungs\\venv\\lib\\site-packages\\PIL\\ImageFile.py:515\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m     fh \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mfileno()\n\u001b[0;32m    516\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sss\\lML_git\\ML_lungs\\preprocessing.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sss/lML_git/ML_lungs/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m download_dataset()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sss/lML_git/ML_lungs/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# build_masks()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sss/lML_git/ML_lungs/preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m preprocess_images()\n",
      "File \u001b[1;32mc:\\Users\\sss\\lML_git\\ML_lungs\\preprocessing.py:35\u001b[0m, in \u001b[0;36mpreprocess_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39m# processing train images\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(in_train_path):\n\u001b[1;32m---> 35\u001b[0m     select_with_mask(\n\u001b[0;32m     36\u001b[0m         in_train_path \u001b[39m/\u001b[39;49m filename,\n\u001b[0;32m     37\u001b[0m         in_train_masks_path \u001b[39m/\u001b[39;49m filename,\n\u001b[0;32m     38\u001b[0m         out_train_path\n\u001b[0;32m     39\u001b[0m     )\n\u001b[0;32m     41\u001b[0m \u001b[39m# processing test images\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(in_test_path):\n",
      "File \u001b[1;32mc:\\Users\\sss\\lML_git\\ML_lungs\\preprocessing.py:12\u001b[0m, in \u001b[0;36mselect_with_mask\u001b[1;34m(pic_path, mask_path, out_dir)\u001b[0m\n\u001b[0;32m     10\u001b[0m plane \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mnew(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m, img\u001b[39m.\u001b[39msize, \u001b[39m0\u001b[39m)\n\u001b[0;32m     11\u001b[0m res \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mcomposite(img, plane, mask)\n\u001b[1;32m---> 12\u001b[0m res\u001b[39m.\u001b[39;49msave(out_dir \u001b[39m/\u001b[39;49m pic_path\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\sss\\lML_git\\ML_lungs\\venv\\lib\\site-packages\\PIL\\Image.py:2438\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2435\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mw+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2438\u001b[0m     save_handler(\u001b[39mself\u001b[39;49m, fp, filename)\n\u001b[0;32m   2439\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   2440\u001b[0m     \u001b[39mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32mc:\\Users\\sss\\lML_git\\ML_lungs\\venv\\lib\\site-packages\\PIL\\PngImagePlugin.py:1394\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1392\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n\u001b[0;32m   1393\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1394\u001b[0m     ImageFile\u001b[39m.\u001b[39;49m_save(im, _idat(fp, chunk), [(\u001b[39m\"\u001b[39;49m\u001b[39mzip\u001b[39;49m\u001b[39m\"\u001b[39;49m, (\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m) \u001b[39m+\u001b[39;49m im\u001b[39m.\u001b[39;49msize, \u001b[39m0\u001b[39;49m, rawmode)])\n\u001b[0;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m info:\n\u001b[0;32m   1397\u001b[0m     \u001b[39mfor\u001b[39;00m info_chunk \u001b[39min\u001b[39;00m info\u001b[39m.\u001b[39mchunks:\n",
      "File \u001b[1;32mc:\\Users\\sss\\lML_git\\ML_lungs\\venv\\lib\\site-packages\\PIL\\ImageFile.py:519\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    517\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[0;32m    518\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation) \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m--> 519\u001b[0m     _encode_tile(im, fp, tile, bufsize, \u001b[39mNone\u001b[39;49;00m, exc)\n\u001b[0;32m    520\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(fp, \u001b[39m\"\u001b[39m\u001b[39mflush\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    521\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\sss\\lML_git\\ML_lungs\\venv\\lib\\site-packages\\PIL\\ImageFile.py:538\u001b[0m, in \u001b[0;36m_encode_tile\u001b[1;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mif\u001b[39;00m exc:\n\u001b[0;32m    536\u001b[0m     \u001b[39m# compress to Python file-compatible object\u001b[39;00m\n\u001b[0;32m    537\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 538\u001b[0m         errcode, data \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mencode(bufsize)[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    539\u001b[0m         fp\u001b[39m.\u001b[39mwrite(data)\n\u001b[0;32m    540\u001b[0m         \u001b[39mif\u001b[39;00m errcode:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision opencv-python kaggle Pillow\n",
    "\n",
    "from download_dataset import download_dataset\n",
    "from mask_building import build_masks\n",
    "from preprocessing import preprocess_images\n",
    "\n",
    "\n",
    "download_dataset()\n",
    "build_masks()\n",
    "preprocess_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у вы работаете только с\n",
    "> ./dataset/data/train_answers.csv \n",
    "\n",
    "> ./dataset/preprocessed_data/train_images/*\n",
    "\n",
    "> ./dataset/preprocessed_data/test_images/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше сами)\n",
    "\n",
    "P.S. Следите за обновлением весов (unet_dump.pt) и скриптов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
